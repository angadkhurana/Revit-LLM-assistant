{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import VectorDBQA\n",
    "from langchain.chains import RetrievalQA\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a chatbot having a conversation with a human.\"\n",
    "        ),  # The persistent system prompt\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\"\n",
    "        ),  # Where the memory will be stored.\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\"\n",
    "        ),  # Where the human input will injected\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4')\n",
    "\n",
    "# llm = OpenAI(model='gpt-4-vision-preview')\n",
    "\n",
    "chat_llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=False,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "# chat_llm_chain.predict(human_input=\"my name is angad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# chat = ChatOpenAI(model=\"gpt-4-vision-preview\")\n",
    "# chat.invoke(\n",
    "#     [\n",
    "#         HumanMessage(\n",
    "#             content=[\n",
    "#                 {\"type\": \"text\", \"text\": \"\"\"I'm giving you an image of a floorplan.\n",
    "#                  \"\"\"},\n",
    "#                 {\n",
    "#                     \"type\": \"image_url\",\n",
    "#                     \"image_url\": {\n",
    "#                         \"url\": \"https://www.grundriss-schmiede.de/images/buerogrundriss/buerogrundriss.png\",\n",
    "#                         \"detail\": \"auto\",\n",
    "#                     },\n",
    "#                 },\n",
    "#             ]\n",
    "#         )\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(input_string, max_length=180):\n",
    "    # max_length = 125\n",
    "    chunks = []\n",
    "\n",
    "    current_chunk = \"\"\n",
    "    for char in input_string:\n",
    "        if char == '\\n' or len(current_chunk) == max_length:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = \"\"\n",
    "        else:\n",
    "            current_chunk += char\n",
    "\n",
    "    # Append the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_x = [31792.864927,\n",
    "31792.864927,\n",
    "31792.864927,\n",
    "24204.196911,\n",
    "23086.27139,\n",
    "24447.946444,\n",
    "24447.946444,\n",
    "20588.750971,\n",
    "20588.750971,\n",
    "19556.033119,\n",
    "21498.338399,\n",
    "19178.890458,\n",
    "19178.890458,\n",
    "11325.642678,\n",
    "11325.642678,\n",
    "15559.078562,\n",
    "16404.648802,\n",
    "9701.790319,\n",
    "15138.40578,\n",
    "5999.464942,\n",
    "24477.237227,\n",
    "24477.237227,\n",
    "21498.338399,\n",
    "19178.890458,\n",
    "19178.890458,\n",
    "16404.648802,\n",
    "13996.418764,\n",
    "15138.40578,\n",
    "11093.15454,\n",
    "21437.644176,\n",
    "19789.016963,\n",
    "24447.946444,\n",
    "31792.864927,\n",
    "34635.32564,\n",
    "5999.464942,\n",
    "3222.696981,\n",
    "23086.27139,\n",
    "23086.27139,\n",
    "19789.016963,\n",
    "19789.016963,\n",
    "23086.27139,\n",
    "11093.15454,\n",
    "11093.15454,\n",
    "5999.464942,\n",
    "5999.464942,\n",
    "9174.174248,\n",
    "11093.15454,\n",
    "552.603696,\n",
    "37394.984283,\n",
    "37394.984283,\n",
    "552.603696,\n",
    "3498.761184,\n",
    "9391.632409,\n",
    "9391.632409,\n",
    "3498.761184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_x = [31792.864927,\n",
    "31792.864927,\n",
    "31792.864927,\n",
    "24447.946444,\n",
    "23626.664256,\n",
    "24447.946444,\n",
    "24447.946444,\n",
    "20588.750971,\n",
    "20588.750971,\n",
    "19178.890458,\n",
    "20133.565773,\n",
    "19178.890458,\n",
    "19178.890458,\n",
    "11325.642678,\n",
    "11325.642678,\n",
    "11325.642678,\n",
    "16136.611217,\n",
    "9391.632409,\n",
    "10279.322973,\n",
    "5999.464942,\n",
    "24477.237227,\n",
    "20588.750971,\n",
    "21498.338399,\n",
    "19178.890458,\n",
    "16404.648802,\n",
    "16404.648802,\n",
    "13996.418764,\n",
    "15138.40578,\n",
    "11093.15454,\n",
    "21437.644176,\n",
    "11093.15454,\n",
    "31792.864927,\n",
    "34635.32564,\n",
    "34635.32564,\n",
    "3222.696981,\n",
    "3222.696981,\n",
    "23086.27139,\n",
    "19789.016963,\n",
    "19789.016963,\n",
    "23086.27139,\n",
    "23086.27139,\n",
    "11093.15454,\n",
    "5999.464942,\n",
    "5999.464942,\n",
    "8596.641594,\n",
    "11093.15454,\n",
    "11093.15454,\n",
    "37394.984283,\n",
    "37394.984283,\n",
    "552.603696,\n",
    "552.603696,\n",
    "9391.632409,\n",
    "9391.632409,\n",
    "3498.761184,\n",
    "3498.761184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_y = [-2379.722858,\n",
    "1493.872839,\n",
    "3835.711592,\n",
    "15.444393,\n",
    "15.444393,\n",
    "2654.279001,\n",
    "3835.711592,\n",
    "7404.962615,\n",
    "5132.58684,\n",
    "7633.952267,\n",
    "7633.952267,\n",
    "6706.490993,\n",
    "7633.952267,\n",
    "8399.596468,\n",
    "7355.592694,\n",
    "7355.592694,\n",
    "7355.592694,\n",
    "5132.58684,\n",
    "5132.58684,\n",
    "-2189.956245,\n",
    "11520.517391,\n",
    "5132.58684,\n",
    "11520.517391,\n",
    "7633.952267,\n",
    "5132.58684,\n",
    "5132.58684,\n",
    "11520.517391,\n",
    "7355.592694,\n",
    "-527.87009,\n",
    "15.444393,\n",
    "3835.711592,\n",
    "3835.711592,\n",
    "-941.851185,\n",
    "-941.851185,\n",
    "-527.87009,\n",
    "-527.87009,\n",
    "2063.410443,\n",
    "3835.711592,\n",
    "3835.711592,\n",
    "15.444393,\n",
    "15.444393,\n",
    "3150.140023,\n",
    "3835.711592,\n",
    "3835.711592,\n",
    "-527.87009,\n",
    "-527.87009,\n",
    "-527.87009,\n",
    "-4561.199065,\n",
    "-4561.199065,\n",
    "11520.517391,\n",
    "11520.517391,\n",
    "5132.58684,\n",
    "5132.58684,\n",
    "7628.666651,\n",
    "7628.666651]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_y = [-4561.199065,\n",
    "-1727.143587,\n",
    "2247.601897,\n",
    "15.444393,\n",
    "15.444393,\n",
    "-4561.199065,\n",
    "3408.008059,\n",
    "7633.952267,\n",
    "6651.233557,\n",
    "7633.952267,\n",
    "7633.952267,\n",
    "5132.58684,\n",
    "7460.220051,\n",
    "11520.517391,\n",
    "7645.86741,\n",
    "7355.592694,\n",
    "7355.592694,\n",
    "5132.58684,\n",
    "5132.58684,\n",
    "-4561.199065,\n",
    "5132.58684,\n",
    "5132.58684,\n",
    "7633.952267,\n",
    "11520.517391,\n",
    "5132.58684,\n",
    "11520.517391,\n",
    "7355.592694,\n",
    "5132.58684,\n",
    "-4561.199065,\n",
    "-4561.199065,\n",
    "3835.711592,\n",
    "3835.711592,\n",
    "-941.851185,\n",
    "-4561.199065,\n",
    "-527.87009,\n",
    "-4561.199065,\n",
    "3835.711592,\n",
    "3835.711592,\n",
    "15.444393,\n",
    "15.444393,\n",
    "1309.681385,\n",
    "3835.711592,\n",
    "3835.711592,\n",
    "-527.87009,\n",
    "-527.87009,\n",
    "-527.87009,\n",
    "2396.410965,\n",
    "-4561.199065,\n",
    "11520.517391,\n",
    "11520.517391,\n",
    "-4561.199065,\n",
    "5132.58684,\n",
    "7628.666651,\n",
    "7628.666651,\n",
    "5132.58684]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Imagine an x-y cartesian grid with precision of 1 metre. Point A is at (2385,4933) and Point B is at (34406,4933).\n",
    "What is the distance from point A to point B.\"\"\"\n",
    "for i in range(len(start_x)-40):\n",
    "    s = \"Rule {} : YOU CANNOT CROSS THE LINE FROM ({},{}) TO ({},{})\".format(i+1,int(start_x[i]),int(start_y[i]),int(end_x[i]),int(end_y[i]))\n",
    "    prompt = prompt + s + \"\\n\"\n",
    "\n",
    "prompt = prompt + \"\"\"AT EACH STEP, GO THROUGH ALL RULES TO CHECK IF EVERY RULE IS BEING OBEYED. EXPLAIN\n",
    "THE ANSWER FOR EACH RULE. YOU CAN MOVE DIAGONALLY.\n",
    "YOU CAN ALSO MOVE JUST BESIDE THE WALLS/OBSTACLES.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "\n",
    "loader = TextLoader(\"fire_life_safety.md\")\n",
    "md_text = loader.load()[0].page_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, how can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "# q_string = \"\"\"Imagine an x-y cartesian grid with precision of 1 metre. Point A is at (100,100) and Point B is at (500,200).\n",
    "# What is the distance from point A to point B.\n",
    "# There are the following 3 rules to be obeyed during the journey.\n",
    "# Rule 1: YOU CANNOT CROSS THE LINE FROM (200,0) TO (200,200). THIS WALL HAS AN OPENING FROM (200,20) TO (200,30).\n",
    "# Rule 2: YOU CANNOT CROSS THE LINE FROM (200,200) TO (300,200).\n",
    "# Rule 3: YOU CANNOT CROSS THE LINE FROM (400,100) TO (400,300).\n",
    "# Rule 4: 0<x<600 & 0<y<300 for any point during the journey.\n",
    "# Rule 5: yOU CAN GO TO THE OTHER SIDE OF THE WALLS THROUGH THE OPENINGS IF MENTIONED. CHECK If going through them is the shorter path, do it.\n",
    "\n",
    "# AT EACH STEP, GO THROUGH ALL RULES TO CHECK IF EVERY RULE IS BEING OBEYED. EXPLAIN\n",
    "# THE ANSWER FOR EACH RULE. YOU CAN MOVE DIAGONALLY.\n",
    "# YOU CAN ALSO MOVE JUST BESIDE THE WALLS/OBSTACLES.\"\"\"\n",
    "\n",
    "q_string = \"\"\"\n",
    "1. Worked as a part of The Pissarides Review into the Future of Work and Wellbeing (Website) led by Nobel Prize-\n",
    "winning economist Professor Sir Christopher Pissarides. The review aims to quantify the amount of technological disruption in UK using a measure named Disruption Index (DI).\n",
    "2. Utilised Partial Distance Correlation to consider confounding variables and analyze the relationship among variables used to calculate DI.\n",
    "3. Performed data analysis to extract valuable insights to identify the technological evolution of different geographic areas\n",
    "4. Conducted clustering analysis on a graph where nodes represented skills extracted from job advertisements. Utilized the\n",
    "severability method (arxiv/severability) to discern evolving skill clusters over time within a specific profession\n",
    "5. Modified the open source code for the severability package (github/severability) to remove bugs and add functionality\n",
    "\n",
    "Reduce the word count for each point.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "q_string = \"\"\"\n",
    "1. Compared the new EPIC Deterioration Index mortality prediction model with the existing MEWS model in the hospital to\n",
    "assess the benefits of adopting the new prediction model.\n",
    "2. Determined optimum model thresholds for best model performance for various medical departments.\n",
    "3. Demonstrated that the new model performed better in terms of true positives and false negatives.\n",
    "\n",
    "Summarise these points in less than 25 words\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "q_string = \"\"\"\n",
    "1. Developed a C# desktop telemetry app to receive and analyze real-time data from a student F1 car.\n",
    "2. Utilised User Datagram Protocol (UDP) to transfer data from the car over wifi at a rate of 40 Hz.\n",
    "3. Utilised Matlab and Simulink to set up the transmission of data in UDP packets from the car.\n",
    "\n",
    "Summarise these points in less than 25 words\n",
    "\"\"\"\n",
    "# 4. Conducted clustering analysis on a graph where nodes represented skills extracted from job advertisements. \n",
    "large_string = chat_llm_chain.predict(human_input=q_string)\n",
    "\n",
    "# Split the string using the newline character\n",
    "lines = split_string(large_string)\n",
    "\n",
    "# Print each line\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a chatbot, I'm not equipped to visually analyze and calculate the exact path on an x-y Cartesian grid based on the numerous rules provided, especially in a text-based environmen\n",
      ". This task requires a specific type of software developed for graphical or spatial analysis, like pathfinding algorithms in a GIS (Geographic Information System) software, or algo\n",
      "ithms like A* or Dijkstra's algorithm.\n",
      "\n",
      "However, I can provide a general strategy:\n",
      "\n",
      "1. Start at point A (2385,4933).\n",
      "2. Navigate around the restrictions by moving toward the next available point that is closest to point B (34406,4933) without crossing any restricted lines.\n",
      "3. Continue this process, always moving toward point B while avoiding restricted lines, until you reach point B.\n",
      "\n",
      "Please note that the exact path would depend on the specific configuration and placement of the restrictions, and therefore cannot be accurately determined without using a graphica\n",
      " representation or spatial analysis software.\n",
      "\n",
      "It's recommended to use a professional pathfinding tool or software that can calculate the shortest path factoring in these restrictions. These tools will be able to provide a much\n",
      "more accurate and efficient path.\n"
     ]
    }
   ],
   "source": [
    "q_string = \"\"\"give the path. even if its an estimate\"\"\"\n",
    "# Provide me with a detailed description or visualization of the resulting maze in the X-Y plane format.\n",
    "large_string = chat_llm_chain.predict(human_input=q_string)\n",
    "\n",
    "# Split the string using the newline character\n",
    "lines = split_string(large_string)\n",
    "\n",
    "# Print each line\n",
    "for line in lines:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry for the confusion, but as a text-based AI, I don't have the ability to process files or view content like a human would. I can provide information and answer questions ba\n",
      "ed on the text inputs I receive. If you have specific questions about your .bxf or .dwg files, feel free to ask and I'll do my best to help!\n"
     ]
    }
   ],
   "source": [
    "q_string = \"\"\"can i give u .bxf or .dwg files\"\"\"\n",
    "\n",
    "large_string = chat_llm_chain.predict(human_input=q_string)\n",
    "\n",
    "# Split the string using the newline character\n",
    "lines = split_string(large_string)\n",
    "\n",
    "# Print each line\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "revit_llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
