{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import VectorDBQA\n",
    "from langchain.chains import RetrievalQA\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a chatbot having a conversation with a human.\"\n",
    "        ),  # The persistent system prompt\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\"\n",
    "        ),  # Where the memory will be stored.\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\"\n",
    "        ),  # Where the human input will injected\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4')\n",
    "\n",
    "# llm = OpenAI(model='gpt-4-vision-preview')\n",
    "\n",
    "chat_llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=False,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "# chat_llm_chain.predict(human_input=\"my name is angad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# chat = ChatOpenAI(model=\"gpt-4-vision-preview\")\n",
    "# chat.invoke(\n",
    "#     [\n",
    "#         HumanMessage(\n",
    "#             content=[\n",
    "#                 {\"type\": \"text\", \"text\": \"\"\"I'm giving you an image of a floorplan.\n",
    "#                  \"\"\"},\n",
    "#                 {\n",
    "#                     \"type\": \"image_url\",\n",
    "#                     \"image_url\": {\n",
    "#                         \"url\": \"https://www.grundriss-schmiede.de/images/buerogrundriss/buerogrundriss.png\",\n",
    "#                         \"detail\": \"auto\",\n",
    "#                     },\n",
    "#                 },\n",
    "#             ]\n",
    "#         )\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(input_string, max_length=180):\n",
    "    # max_length = 125\n",
    "    chunks = []\n",
    "\n",
    "    current_chunk = \"\"\n",
    "    for char in input_string:\n",
    "        if char == '\\n' or len(current_chunk) == max_length:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = \"\"\n",
    "        else:\n",
    "            current_chunk += char\n",
    "\n",
    "    # Append the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the path and its compliance with the rules:\n",
      "\n",
      "Step 1: Start at Point A (100,100). We're allowed to start here as it obeys Rule 4 (0<x<600 and 0<y<300).\n",
      "\n",
      "Step 2: Move diagonally towards the opening in the wall at (200,20) - (200,30). This is the fastest path to the wall. The distance travelled is the Euclidean distance between (100,\n",
      "00) and (200,25), which is approximately 111.8 meters. This route obeys Rule 1 (You cannot cross the line from (200,0) to (200,200) except the opening) and Rule 4.\n",
      "\n",
      "Step 3: Cross through the opening from (200,25) to the other side of the wall. This is a vertical movement of 1 meter (from 25 to 26). This obeys Rule 1 and Rule 4.\n",
      "\n",
      "Step 4: Move diagonally towards the point just below the next wall at (400,100). The Euclidean distance travelled is from (200,26) to (400,100), approximately 186.4 meters. This ob\n",
      "ys Rule 3 (You cannot cross the line from (400,100) to (400,300)) and Rule 4.\n",
      "\n",
      "Step 5: Move diagonally from (400,100) towards point B at (500,200). This route obeys Rule 2 (You cannot cross the line from (200,200) to (300,200)), Rule 3, and Rule 4. The distan\n",
      "e is the Euclidean distance from (400,100) to (500,200), which is approximately 141.4 meters.\n",
      "\n",
      "The total distance travelled from A to B, obeying all the rules, is therefore approximately 111.8 + 1 + 186.4 + 141.4 = 440.6 meters.\n"
     ]
    }
   ],
   "source": [
    "q_string = \"\"\"Imagine an x-y cartesian grid with precision of 1 metre. Point A is at (100,100) and Point B is at (500,200).\n",
    "What is the distance from point A to point B.\n",
    "There are the following 3 rules to be obeyed during the journey.\n",
    "Rule 1: YOU CANNOT CROSS THE LINE FROM (200,0) TO (200,200). THIS WALL HAS AN OPENING FROM (200,20) TO (200,30).\n",
    "Rule 2: YOU CANNOT CROSS THE LINE FROM (200,200) TO (300,200).\n",
    "Rule 3: YOU CANNOT CROSS THE LINE FROM (400,100) TO (400,300).\n",
    "Rule 4: 0<x<600 & 0<y<300 for any point during the journey.\n",
    "Rule 5: yOU CAN GO TO THE OTHER SIDE OF THE WALLS THROUGH THE OPENINGS IF MENTIONED. CHECK If going through them is the shorter path, do it.\n",
    "\n",
    "AT EACH STEP, GO THROUGH ALL RULES TO CHECK IF EVERY RULE IS BEING OBEYED. EXPLAIN\n",
    "THE ANSWER FOR EACH RULE. YOU CAN MOVE DIAGONALLY.\n",
    "YOU CAN ALSO MOVE JUST BESIDE THE WALLS/OBSTACLES.\"\"\"\n",
    "# Keeping these rules in mind, tell if the distance to both point A and point B is more than 45 from any point\n",
    "# in the cartesian plane\"\"\" \n",
    "\n",
    "# 3. There is an obstruction going from (200,0) to (200,200). So i can't go through this obstruction.\n",
    "\n",
    "# q_string = \"\"\"Give code to convert an image of a floorplan to a maze to go from one staircase\n",
    "# to another in python.\"\"\"\n",
    "\n",
    "# q_string = \"\"\"Given a floorplan with walls and two staircases, I want to convert it into an X-Y plane representation and generate a maze. \n",
    "# The walls in the floorplan should be translated into barriers in the maze, and the staircases should serve as entry and exit points.\n",
    "#  Provide me with a detailed description or visualization of the resulting maze in the X-Y plane format.\n",
    "# \"\"\"\n",
    "\n",
    "large_string = chat_llm_chain.predict(human_input=q_string)\n",
    "\n",
    "# Split the string using the newline character\n",
    "lines = split_string(large_string)\n",
    "\n",
    "# Print each line\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry for my previous response. As a text-based AI, I'm unable to create a detailed grid visual. However, I can provide a simple ASCII representation.\n",
      "\n",
      "The grid would look something like this if you imagine each character as a 100 meter step:\n",
      "\n",
      "```\n",
      "P--------------------|          \n",
      "|                    |          \n",
      "|                    |          \n",
      "|                    P          \n",
      "|--------------------|          \n",
      "|                              \n",
      "|                              \n",
      "P                              \n",
      "```\n",
      "In the above representation:\n",
      "\n",
      "- P (Points): A is at the bottom left, B is at the top right.\n",
      "- | (Walls): Represent the restrictions on the path.\n",
      "- - (Path): The trajectory the path needs to follow.\n",
      "\n",
      "Please keep in mind that this is a very simplified version of the grid and does not accurately represent the distances and proportions. For a more accurate visual representation, p\n",
      "ease consider using graph paper or a digital drawing tool.\n"
     ]
    }
   ],
   "source": [
    "q_string = \"\"\"give visual representation using _ | for walls and P for points of the room.\"\"\"\n",
    "# Provide me with a detailed description or visualization of the resulting maze in the X-Y plane format.\n",
    "large_string = chat_llm_chain.predict(human_input=q_string)\n",
    "\n",
    "# Split the string using the newline character\n",
    "lines = split_string(large_string)\n",
    "\n",
    "# Print each line\n",
    "for line in lines:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry for the confusion, but as a text-based AI, I don't have the ability to process files or view content like a human would. I can provide information and answer questions ba\n",
      "ed on the text inputs I receive. If you have specific questions about your .bxf or .dwg files, feel free to ask and I'll do my best to help!\n"
     ]
    }
   ],
   "source": [
    "q_string = \"\"\"can i give u .bxf or .dwg files\"\"\"\n",
    "\n",
    "large_string = chat_llm_chain.predict(human_input=q_string)\n",
    "\n",
    "# Split the string using the newline character\n",
    "lines = split_string(large_string)\n",
    "\n",
    "# Print each line\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "revit_llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
